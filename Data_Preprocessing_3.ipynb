{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_3(filename, output_file):\n",
    "\n",
    "    fo = open(output_file, 'a+')\n",
    "    f = open(filename)\n",
    "    tag_dict = {}\n",
    "    rel_dict = {}\n",
    "    for i in f.readlines():\n",
    "        s = i.split()\n",
    "        if s[0][0]=='T':\n",
    "            k = s[0]\n",
    "            val = ' '.join(s[4:])\n",
    "            tag_dict[k] = val\n",
    "        elif s[0][0]=='*':\n",
    "            k1 = s[2]\n",
    "            k2 = s[3]\n",
    "            rel_dict[k1+k2] = tag_dict[k1]+\" | \"+tag_dict[k2]+\" | \"+str(2)\n",
    "            rel_dict[k2+k1] = tag_dict[k2]+\" | \"+tag_dict[k1]+\" | \"+str(2)\n",
    "        else:\n",
    "            k1 = s[2][5:]\n",
    "            k2 = s[3][5:]\n",
    "            rel_dict[s[0]+\"1\"] = tag_dict[k1]+\" | \"+tag_dict[k2]+\" | \"+str(1)\n",
    "            rel_dict[s[0]+\"2\"] = tag_dict[k2]+\" | \"+tag_dict[k1]+\" | \"+str(0)\n",
    "    for k, v in rel_dict.items():\n",
    "        fo.write(v+\"\\n\")\n",
    "    f.close()\n",
    "    fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = os.listdir(\"train/\")\n",
    "train_files.sort()\n",
    "for i in range(0,len(train_files), 2):\n",
    "    annotation_file = \"train/\"+train_files[i]\n",
    "    # txt_file = \"train/\"+train_files[i+1]\n",
    "    output_file = \"dataset/subtask3/train.txt\"\n",
    "    try:\n",
    "        preprocess_3(annotation_file, output_file)\n",
    "    except:\n",
    "        print(annotation_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = os.listdir(\"test/\")\n",
    "test_files.sort()\n",
    "for i in range(0,len(test_files), 2):\n",
    "    annotation_file = \"test/\"+test_files[i]\n",
    "    # txt_file = \"train/\"+train_files[i+1]\n",
    "    output_file = \"dataset/subtask3/test.txt\"\n",
    "    try:\n",
    "        preprocess_3(annotation_file, output_file)\n",
    "    except:\n",
    "        print(annotation_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_files = os.listdir(\"val/\")\n",
    "val_files.sort()\n",
    "for i in range(0,len(val_files), 2):\n",
    "    annotation_file = \"val/\"+val_files[i]\n",
    "    # txt_file = \"train/\"+train_files[i+1]\n",
    "    output_file = \"dataset/subtask3/val.txt\"\n",
    "    try:\n",
    "        preprocess_3(annotation_file, output_file)\n",
    "    except:\n",
    "        print(annotation_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-project",
   "language": "python",
   "name": "nlp-project"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
